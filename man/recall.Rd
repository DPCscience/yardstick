% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/recall.R
\name{recall}
\alias{recall}
\alias{recall.default}
\alias{recall.table}
\alias{precision}
\alias{precision.default}
\alias{precision.table}
\alias{precision.matrix}
\alias{F_meas}
\alias{F_meas.default}
\alias{F_meas.table}
\alias{recall.table}
\alias{recall.data.frame}
\alias{precision}
\alias{precision.data.frame}
\alias{precision.table}
\alias{F_meas}
\alias{F_meas.default}
\alias{F_meas.table}
\title{Calculate recall, precision and F values}
\usage{
recall(data, ...)

\method{recall}{table}(data, ...)

\method{recall}{data.frame}(data, truth = NULL, estimate = NULL,
  na.rm = TRUE, ...)

precision(data, ...)

\method{precision}{data.frame}(data, truth = NULL, estimate = NULL,
  na.rm = TRUE, ...)

\method{precision}{table}(data, ...)

F_meas(data, ...)

\method{F_meas}{default}(data, truth = NULL, estimate = NULL, beta = 1,
  na.rm = TRUE, ...)

\method{F_meas}{table}(data, beta = 1, ...)
}
\arguments{
\item{data}{For the default functions, a factor containing the
discrete measurements. For the \code{table} function, a table.}

\item{...}{Not currently used.}

\item{truth}{A single character value containing the column
name of \code{data} that contains the true classes (in a factor).}

\item{estimate}{A single character value containing the column
name of \code{data} that contains the predicted classes (in a factor).}

\item{na.rm}{A logical value indicating whether \code{NA} values
should be stripped before the computation proceeds.}

\item{beta}{A numeric value used to weight precision and
recall. A value of 1 is traditionally used and corresponds to
the harmonic mean of the two values but other values weight
recall beta times more important than precision.}
}
\value{
A number between 0 and 1 (or NA).
}
\description{
These functions calculate the recall, precision or F values of
a measurement system for finding/retrieving relevant documents
compared to reference results (the truth regarding relevance).
The measurement and "truth" data must have the same two possible
outcomes and one of the outcomes must be thought of as a
"relevant" results.
}
\details{
The recall (aka specificity) is defined as the proportion of
relevant results out of the number of samples which were
actually relevant. When there are no relevant results, recall is
not defined and a value of \code{NA} is returned.

The precision is percentage of predicted truly relevant results
of the total number of predicted relevant results and
characterizes the "purity in retrieval performance" (Buckland
and Gey, 1994).

The measure "F" is a combination of precision and recall (see
below).

Suppose a 2x2 table with notation

\tabular{rcc}{ \tab Reference \tab \cr Predicted \tab relevant \tab
Irrelevant \cr relevant \tab A \tab B \cr Irrelevant \tab C \tab D \cr }

The formulas used here are: \deqn{recall = A/(A+C)} \deqn{precision =
A/(A+B)} \deqn{F_i = (1+i^2)*prec*recall/((i^2 * precision)+recall)}

See the references for discussions of the statistics.
}
\examples{


}
\references{
Buckland, M., & Gey, F. (1994). The relationship
between Recall and Precision. \emph{Journal of the American Society
for Information Science}, 45(1), 12-19.

Powers, D. (2007). Evaluation: From Precision, Recall and F
Factor to ROC, Informedness, Markedness and Correlation.
Technical Report SIE-07-001, Flinders University
}
\seealso{
\code{\link[=conf_mat]{conf_mat()}}
}
\author{
Max Kuhn
}
\keyword{manip}
